# ML-MCDM Framework

**A Hybrid Multi-Criteria Decision Making Framework with Intuitionistic Fuzzy Sets, Evidential Reasoning, and Ensemble Machine Learning**

[![Python](https://img.shields.io/badge/python-3.8%2B-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)
[![Status](https://img.shields.io/badge/status-production-brightgreen.svg)](https://github.com/hoangsonww/ml-mcdm)

## Overview

This framework combines state-of-the-art Multi-Criteria Decision Making (MCDM) methods with Machine Learning to analyze and forecast multi-dimensional performance across entities. It integrates three major components:

1. **Objective Weighting** via Game Theory Weight Combination (GTWC)
2. **Hierarchical Ranking** using Intuitionistic Fuzzy Sets (IFS) + Evidential Reasoning (ER)
3. **ML Forecasting** via 6-model ensemble + Super Learner + Conformal Prediction

**Application:** Vietnam PAPI (Provincial Governance and Public Administration Performance Index) analysis across 63 provinces over 14 years (2011-2024).

---

## Key Features

### üéØ Hierarchical Ranking System
- **12 MCDM Methods**: 6 Traditional + 6 IFS variants
  - Traditional: TOPSIS, VIKOR, PROMETHEE, COPRAS, EDAS, SAW
  - IFS Extensions: Handles uncertainty via Atanassov's Intuitionistic Fuzzy Sets
- **Two-Stage Architecture**: Within-criterion combination ‚Üí Global aggregation
- **Evidential Reasoning**: Rigorous belief combination (Yang & Xu, 2002)
- **Adaptive Zero-Handling**: Automatic exclusion of missing/zero data with restoration

### ‚öñÔ∏è Objective Weight Calculation
- **4 Complementary Methods**: Entropy, CRITIC, MEREC, Standard Deviation
- **Game Theory Combination**: Intra-group hybridization + cooperative optimization
- **Uncertainty Quantification**: Bayesian Bootstrap (999 iterations)
- **Temporal Stability**: Split-half validation

### ü§ñ Machine Learning Forecasting
- **State-of-the-Art Ensemble**: 6 diverse models optimized for N<1000
  - Gradient Boosting (Huber loss)
  - Bayesian Ridge (uncertainty quantification)
  - Quantile Random Forest (distributional forecasting)
  - Panel VAR (panel-specific dynamics)
  - Hierarchical Bayesian (partial pooling)
  - Neural Additive Models (interpretable non-linearity)
- **Super Learner**: Automatic optimal model weighting via meta-learning
- **Conformal Prediction**: Distribution-free 95% prediction intervals
- **Feature Importance**: Aggregated across all 6 models

### üìä Analysis & Validation
- **Hierarchical Sensitivity Analysis**: Multi-level robustness testing
  - Subcriteria & criteria weight perturbation (¬±15%)
  - IFS uncertainty analysis (Œº/ŒΩ perturbation ¬±10%)
  - Temporal stability (year-to-year correlation)
  - Monte Carlo simulation (100+ iterations)
  - Forecast robustness testing
- **Comprehensive Validation**: End-to-end pipeline validation
  - Cross-level consistency checking
  - IFS parameter validation (Œº + ŒΩ ‚â§ 1)
  - Weight scheme robustness (temporal + method agreement)
  - Forecast quality metrics
- **Convergence Analysis**: Kendall's W concordance coefficient
- **Bootstrap Uncertainty**: Bayesian Bootstrap confidence intervals

---

## System Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Panel Data (N provinces √ó T years √ó p criteria)              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚ñº                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  WEIGHTING   ‚îÇ   ‚îÇ    RANKING      ‚îÇ
‚îÇ              ‚îÇ   ‚îÇ                 ‚îÇ
‚îÇ ‚Ä¢ Entropy    ‚îÇ   ‚îÇ Stage 1: Within ‚îÇ
‚îÇ ‚Ä¢ CRITIC     ‚îÇ‚îÄ‚îÄ‚ñ∫‚îÇ  - Traditional  ‚îÇ
‚îÇ ‚Ä¢ MEREC      ‚îÇ   ‚îÇ  - IFS-MCDM     ‚îÇ
‚îÇ ‚Ä¢ Std Dev    ‚îÇ   ‚îÇ  - ER Combine   ‚îÇ
‚îÇ              ‚îÇ   ‚îÇ                 ‚îÇ
‚îÇ Game Theory  ‚îÇ   ‚îÇ Stage 2: Global ‚îÇ
‚îÇ Combination  ‚îÇ   ‚îÇ  - ER Aggregate ‚îÇ
‚îÇ              ‚îÇ   ‚îÇ  - Final Rank   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
               ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
               ‚ñº            ‚ñº            ‚ñº
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇML FORECAST‚îÇ ‚îÇ ANALYSIS  ‚îÇ ‚îÇ VISUALISE ‚îÇ
        ‚îÇ (OPTIONAL)‚îÇ ‚îÇ           ‚îÇ ‚îÇ & EXPORT  ‚îÇ
        ‚îÇ           ‚îÇ ‚îÇ‚Ä¢ Sensitiv.‚îÇ ‚îÇ           ‚îÇ
        ‚îÇ‚Ä¢ 6 Models ‚îÇ ‚îÇ‚Ä¢ Robust.  ‚îÇ ‚îÇ‚Ä¢ 5 charts ‚îÇ
        ‚îÇ‚Ä¢ Super L  ‚îÇ ‚îÇ‚Ä¢ Kendall W‚îÇ ‚îÇ‚Ä¢ 14 files ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Project Structure

```
ml-mcdm/
‚îú‚îÄ‚îÄ main.py                 # Entry point
‚îú‚îÄ‚îÄ pyproject.toml          # Package configuration & dependencies
‚îÇ
‚îú‚îÄ‚îÄ data/                   # Input data
‚îÇ   ‚îú‚îÄ‚îÄ 2011-2024.csv      # Historical panel data
‚îÇ   ‚îî‚îÄ‚îÄ codebook/          # Variable descriptions
‚îÇ
‚îú‚îÄ‚îÄ pipeline.py            # Main orchestrator
‚îú‚îÄ‚îÄ config.py              # Configuration management
‚îú‚îÄ‚îÄ data_loader.py         # Data I/O and validation
‚îú‚îÄ‚îÄ logger.py              # Logging system
‚îú‚îÄ‚îÄ output_manager.py      # Results export
‚îú‚îÄ‚îÄ visualization.py       # Chart generation (300 DPI)
‚îÇ
‚îú‚îÄ‚îÄ weighting/             # Weight calculation
‚îÇ   ‚îú‚îÄ‚îÄ entropy.py
‚îÇ   ‚îú‚îÄ‚îÄ critic.py
‚îÇ   ‚îú‚îÄ‚îÄ merec.py
‚îÇ   ‚îú‚îÄ‚îÄ standard_deviation.py
‚îÇ   ‚îú‚îÄ‚îÄ fusion.py          # Game Theory Combination
‚îÇ   ‚îî‚îÄ‚îÄ hybrid_weighting.py  # Main interface
‚îÇ
‚îú‚îÄ‚îÄ mcdm/                  # MCDM methods
‚îÇ   ‚îú‚îÄ‚îÄ traditional/       # Traditional MCDM
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ topsis.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ vikor.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ promethee.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ copras.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ edas.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ saw.py
‚îÇ   ‚îî‚îÄ‚îÄ ifs/               # Intuitionistic Fuzzy Sets
‚îÇ       ‚îú‚îÄ‚îÄ base.py
‚îÇ       ‚îú‚îÄ‚îÄ ifs_topsis.py
‚îÇ       ‚îú‚îÄ‚îÄ ifs_vikor.py
‚îÇ       ‚îú‚îÄ‚îÄ ifs_promethee.py
‚îÇ       ‚îú‚îÄ‚îÄ ifs_copras.py
‚îÇ       ‚îú‚îÄ‚îÄ ifs_edas.py
‚îÇ       ‚îî‚îÄ‚îÄ ifs_saw.py
‚îÇ
‚îú‚îÄ‚îÄ evidential_reasoning/  # ER aggregation
‚îÇ   ‚îú‚îÄ‚îÄ base.py            # BeliefDistribution, ER engine
‚îÇ   ‚îî‚îÄ‚îÄ hierarchical_er.py # Two-stage hierarchical ER
‚îÇ
‚îú‚îÄ‚îÄ ranking/               # Ranking orchestrator
‚îÇ   ‚îî‚îÄ‚îÄ pipeline.py        # Hierarchical ranking pipeline
‚îÇ
‚îú‚îÄ‚îÄ analysis/              # Production-ready analysis
‚îÇ   ‚îú‚îÄ‚îÄ sensitivity.py     # Hierarchical sensitivity (565 lines)
‚îÇ   ‚îî‚îÄ‚îÄ validation.py      # Comprehensive validation (533 lines)
‚îÇ
‚îú‚îÄ‚îÄ forecasting/           # Machine learning (experimental)
‚îÇ   ‚îú‚îÄ‚îÄ base.py
‚îÇ   ‚îú‚îÄ‚îÄ features.py        # Feature engineering
‚îÇ   ‚îú‚îÄ‚îÄ tree_ensemble.py   # GB, RF, ET
‚îÇ   ‚îú‚îÄ‚îÄ linear.py          # Bayesian, Huber, Ridge
‚îÇ   ‚îú‚îÄ‚îÄ neural.py          # MLP, Attention
‚îÇ   ‚îî‚îÄ‚îÄ unified.py         # Ensemble orchestrator
‚îÇ
‚îú‚îÄ‚îÄ tests/                 # Test suite
‚îÇ   ‚îî‚îÄ‚îÄ weighting/         # Weighting module tests
‚îÇ
‚îú‚îÄ‚îÄ outputs/               # Generated results (git-ignored)
‚îÇ   ‚îú‚îÄ‚îÄ figures/          # PNG charts (300 DPI)
‚îÇ   ‚îú‚îÄ‚îÄ results/          # CSV files
‚îÇ   ‚îú‚îÄ‚îÄ reports/          # Text reports
‚îÇ   ‚îî‚îÄ‚îÄ logs/             # Debug logs
‚îÇ
‚îî‚îÄ‚îÄ docs/                  # Documentation
    ‚îú‚îÄ‚îÄ objective.md       # Project objectives
    ‚îú‚îÄ‚îÄ dataset_description.md  # Data description
    ‚îú‚îÄ‚îÄ workflow.md        # Pipeline workflow
    ‚îú‚îÄ‚îÄ weighting.md       # Weight calculation details
    ‚îú‚îÄ‚îÄ ranking.md         # IFS+ER ranking methodology
    ‚îî‚îÄ‚îÄ forecast.md        # ML forecasting methods
```

---

## Documentation

### Core Documentation

| Document | Description |
|----------|-------------|
| [objective.md](docs/objective.md) | Project objectives and research questions |
| [dataset_description.md](docs/dataset_description.md) | Data structure and variables |
| [workflow.md](docs/workflow.md) | Pipeline workflow and execution |

### Technical Documentation

| Document | Description |
|----------|-------------|
| [weighting.md](docs/weighting.md) | Game Theory Weight Combination (GTWC) methodology |
| [ranking.md](docs/ranking.md) | IFS-MCDM + Evidential Reasoning details |
| [forecast.md](docs/forecast.md) | Ensemble ML forecasting architecture |

---

## Methodology Highlights

### Intuitionistic Fuzzy Sets (IFS)

Extends classical fuzzy sets by introducing independent non-membership:

$$
\text{IFN} = (\mu, \nu, \pi)
$$

Where:
- **Œº (mu)**: Membership degree ‚àà [0, 1]
- **ŒΩ (nu)**: Non-membership degree ‚àà [0, 1]
- **œÄ (pi)**: Hesitancy = 1 - Œº - ŒΩ
- **Constraint**: Œº + ŒΩ ‚â§ 1

**Construction from temporal data:**
- Œº: Normalized current value
- ŒΩ: Temporal variance (historical std)
- œÄ: Unexplained uncertainty

**Reference:** Atanassov, K.T. (1986). Intuitionistic fuzzy sets. *Fuzzy Sets and Systems*, 20(1), 87-96.

---

### Evidential Reasoning (ER)

Combines multiple assessments into belief distributions over evaluation grades:

$$
\text{Belief} = \{(\text{Excellent}, \beta_E), (\text{Good}, \beta_G), (\text{Fair}, \beta_F), (\text{Poor}, \beta_P), (\text{Bad}, \beta_B), (H, \beta_H)\}
$$

**Pairwise combination:**
$$
\beta_n = K \left[\beta_{1,n}\beta_{2,n} + \beta_{1,n}\beta_{2,H} + \beta_{1,H}\beta_{2,n}\right]
$$

Where K is normalization constant handling conflicts.

**Two-stage architecture:**
1. **Stage 1**: Within each criterion, combine 12 method scores via ER
2. **Stage 2**: Combine 8 criterion beliefs via weighted ER

**Reference:** Yang, J.B., & Xu, D.L. (2002). On the evidential reasoning algorithm. *IEEE Trans. SMC-A*, 32(3), 289-304.

---

### Game Theory Weight Combination (GTWC)

Combines 4 weighting methods through:

1. **Intra-Group Hybridization:**
   - Group A (Dispersion): Geometric mean of Entropy + Std Dev
   - Group B (Interaction): Harmonic mean of CRITIC + MEREC

2. **Cooperative Game Optimization:**
   $$
   \min L = \|Œ±_1W_A + Œ±_2W_B - W_A\|^2 + \|Œ±_1W_A + Œ±_2W_B - W_B\|^2
   $$

3. **Final Aggregation:**
   $$
   W^* = Œ±_1 \cdot W_{\text{GroupA}} + Œ±_2 \cdot W_{\text{GroupB}}
   $$

4. **Bayesian Bootstrap:** 999 iterations for uncertainty quantification

---

### ML Forecasting

The pipeline integrates state-of-the-art ensemble forecasting with 6 diverse
models (Gradient Boosting, Bayesian Ridge, Quantile Forest, Panel VAR,
Hierarchical Bayes, Neural Additive Models). Super Learner meta-ensemble
automatically optimizes model weights, with conformal prediction providing
distribution-free uncertainty intervals.

---

## Output Files

### Results (CSV)

| File | Description |
|------|-------------|
| `final_rankings.csv` | Final province rankings with ER scores |
| `criterion_weights.csv` | GTWC weights with bootstrap uncertainty |
| `mcdm_scores_C01‚ÄìC08.csv` | Per-criterion scores from 12 methods |
| `mcdm_rank_comparison.csv` | Rank comparison across MCDM methods |
| `weights_analysis.csv` | Weight derivation details |
| `forecast_feature_importance.csv` | Aggregated from 6 forecast models (optional) |
| `forecast_cv_metrics.csv` | Cross-validation performance (optional) |
| **`sensitivity_subcriteria.csv`** | **28 subcriteria sensitivity scores** |
| **`sensitivity_criteria.csv`** | **8 criteria sensitivity scores** |
| **`temporal_stability.csv`** | **Year-to-year rank correlations** |
| **`top_n_stability.csv`** | **Top-N ranking stability metrics** |
| **`ifs_sensitivity.csv`** | **IFS Œº/ŒΩ uncertainty analysis** |
| `robustness_summary.csv` | Overall robustness + confidence level |
| `prediction_uncertainty_er.csv` | ER belief-structure uncertainty |
| `data_summary_statistics.csv` | Descriptive statistics of input data |
| `execution_summary.json` | Pipeline timing and metadata |
| `config_snapshot.json` | Full configuration used |

### Figures (PNG, 300 DPI)

- Final ranking summary chart
- Score distribution across provinces
- Weight comparison across criteria
- Sensitivity analysis heatmap
- Feature importance bar chart

### Reports (TXT)

- `report.txt`: Comprehensive analysis summary
- `debug.log`: Detailed execution log

---

## License

MIT License - see [LICENSE](LICENSE) for details.

---

## References

### Core Methodologies

1. **Atanassov, K.T.** (1986). Intuitionistic fuzzy sets. *Fuzzy Sets and Systems*, 20(1), 87-96.

2. **Yang, J.B., & Xu, D.L.** (2002). On the evidential reasoning algorithm for multiple attribute decision analysis under uncertainty. *IEEE Transactions on Systems, Man, and Cybernetics‚ÄîPart A*, 32(3), 289-304.

3. **Hwang, C.L., & Yoon, K.** (1981). *Multiple Attribute Decision Making: Methods and Applications*. Springer.

4. **Keshavarz-Ghorabaee, M., et al.** (2021). Determination of Objective Weights Using a New Method Based on the Removal Effects of Criteria (MEREC). *Symmetry*, 13(4), 525.

5. **Diakoulaki, D., Mavrotas, G., & Papayannakis, L.** (1995). Determining objective weights in multiple criteria problems: The CRITIC method. *Computers & Operations Research*, 22(7), 763-770.

6. **Friedman, J.H.** (2001). Greedy function approximation: A gradient boosting machine. *Annals of Statistics*, 29(5), 1189-1232.

7. **Breiman, L.** (2001). Random forests. *Machine Learning*, 45(1), 5-32.